## About Me

I'm a Robotics Researcher passionate about developing advanced robotic perception systems. My expertise includes developing navigation systems using SLAM algorithms, and utilizing perception sensors like stereo and RGB-D cameras, and LiDAR for autonomous navigation. I have experience in geometric computations on pointclouds, and vision processings for object detection, segmentation, and real-time feedback. Additionally, I'm skilled in ROS and integrating sensory data for comprehensive robotic solutions.


## Projects

### Cybathlon VIS Challenge - FUM iSense Group

<table> <tr> <td> <img src="https://github.com/FUM-Isense/.github/raw/main/profile/media/pilots.png?raw=true" alt="Project Image" style="width:700px;"> </td> <td> <p>The Cybathlon is an international competition organized by ETH Zurich that offers a platform for teams from around the world to develop assistive technologies aimed at improving daily life for people with disabilities. One of the competition's disciplines, the Vision Assistance Race, specifically targets solutions for individuals with visual impairments. As a member of iSense, I participated in this challenge during the Cybathlon 2024.</p> <p><strong>Repository:</strong> <a href="https://github.com/FUM-Isense" target="_blank">View on GitHub</a></p> <p><strong>Webpage:</strong> <a href="https://cybathlon.ethz.ch/en/teams/i-sense" target="_blank">View Team's Page</a></p> </td> </tr> </table>

---

### Amazon Deepracer - Robot Perception Lab

<table> <tr> <td> <img src="https://d1.awsstatic.com/deepracer/DR_Open-Source_Evo%20Image.14c6eb74f8b164e28d693a9e6538f9088a9a86b9.png" alt="Project Image" style="width:650px;"> </td> <td> <p>The AWS DeepRacer Evo is a 1/18th scale, Wi-Fi-enabled vehicle featuring four-wheel Ackermann steering. It is equipped with two RGB cameras and a 2D LiDAR sensor. As a research assistant in the Robot Perception Lab, I focused on using various configurations for navigation, simultaneous localization and mapping (SLAM), and control of the vehicle through the Robot Operating System (ROS).</p> <p><strong>Repository:</strong> <a href="https://github.com/redHaunter/aws-deepracer" target="_blank">View on GitHub</a></p> <p><strong>Webpage:</strong> <a href="https://aws.amazon.com/deepracer/" target="_blank">View Deepracer's Page</a></p> </td> </tr> </table>

---

### Eddiebot Robot - Introduction to Robotics Course

<table> <tr> <td> <img src="https://wiki.ros.org/eddiebot?action=AttachFile&do=get&target=eddie.jpg" alt="Project Image" style="width:650px;"> </td> <td> <p>The Eddiebot is a differential drive mobile robot equipped with a Microsoft Kinect, multiple sonar and infrared sensors, and wheel encoders. I have modified several package configurations and launch files to enhance Simultaneous Localization and Mapping (SLAM).</p> <p><strong>Repository:</strong> <a href="https://github.com/redHaunter/eddiebot-documents" target="_blank">View on GitHub</a></p> <p><strong>Webpage:</strong> <a href="https://wiki.ros.org/eddiebot" target="_blank">View Eddiebot's Page</a></p> </td> </tr> </table>